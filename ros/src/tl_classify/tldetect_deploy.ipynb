{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-03540189e091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "os.chdir(cwd+'/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLClassifier(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.signal_classes = ['Red', 'Green', 'Yellow']\n",
    "       \n",
    "        self.signal_status = None\n",
    "        \n",
    "        self.tl_box = None\n",
    "        \n",
    "        os.chdir(cwd)\n",
    "        \n",
    "        #keras classification model\n",
    "        self.cls_model = load_model('tl_model_1.h5')\n",
    "        \n",
    "        #tensorflow localization/detection model\n",
    "       \n",
    "        detect_model_name = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "        #detect_model_name = 'ssd_inception_v2_coco_11_06_2017'\n",
    "        PATH_TO_CKPT = detect_model_name + '/frozen_inference_graph.pb'\n",
    "        # setup tensorflow graph\n",
    "        self.detection_graph = tf.Graph()\n",
    "        \n",
    "        # configuration for possible GPU use\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        # load frozen tensorflow detection model and initialize \n",
    "        # the tensorflow graph\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "               serialized_graph = fid.read()\n",
    "               od_graph_def.ParseFromString(serialized_graph)\n",
    "               tf.import_graph_def(od_graph_def, name='')\n",
    "               \n",
    "            self.sess = tf.Session(graph=self.detection_graph, config=config)\n",
    "            self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "              # Each box represents a part of the image where a particular object was detected.\n",
    "            self.boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "              # Each score represent how level of confidence for each of the objects.\n",
    "              # Score is shown on the result image, together with the class label.\n",
    "            self.scores =self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            self.classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            self.num_detections =self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "    # Helper function to convert image into numpy array    \n",
    "    def load_image_into_numpy_array(self, image):\n",
    "         (im_width, im_height) = image.size\n",
    "         return np.array(image.getdata()).reshape(\n",
    "            (im_height, im_width, 3)).astype(np.uint8)       \n",
    "    # Helper function to convert normalized box coordinates to pixels\n",
    "    def box_normal_to_pixel(self, box, dim):\n",
    "    \n",
    "        height, width = dim[0], dim[1]\n",
    "        box_pixel = [int(box[0]*height), int(box[1]*width), int(box[2]*height), int(box[3]*width)]\n",
    "        return np.array(box_pixel)       \n",
    "        \n",
    "    def get_localization(self, image, visual=False):  \n",
    "        \"\"\"Determines the locations of the traffic light in the image\n",
    "        Args:\n",
    "            image: camera image\n",
    "        Returns:\n",
    "            list of integers: coordinates [x_left, y_up, x_right, y_down]\n",
    "        \"\"\"\n",
    "        category_index={1: {'id': 1, 'name': u'person'},\n",
    "                        2: {'id': 2, 'name': u'bicycle'},\n",
    "                        3: {'id': 3, 'name': u'car'},\n",
    "                        4: {'id': 4, 'name': u'motorcycle'},\n",
    "                        5: {'id': 5, 'name': u'airplane'},\n",
    "                        6: {'id': 6, 'name': u'bus'},\n",
    "                        7: {'id': 7, 'name': u'train'},\n",
    "                        8: {'id': 8, 'name': u'truck'},\n",
    "                        9: {'id': 9, 'name': u'boat'},\n",
    "                        10: {'id': 10, 'name': u'traffic light'},\n",
    "                        11: {'id': 11, 'name': u'fire hydrant'},\n",
    "                        13: {'id': 13, 'name': u'stop sign'},\n",
    "                        14: {'id': 14, 'name': u'parking meter'}}  \n",
    "        with self.detection_graph.as_default():\n",
    "              image_expanded = np.expand_dims(image, axis=0)\n",
    "              (boxes, scores, classes, num_detections) = self.sess.run(\n",
    "                  [self.boxes, self.scores, self.classes, self.num_detections],\n",
    "                  feed_dict={self.image_tensor: image_expanded})\n",
    "          \n",
    "              if visual == True:\n",
    "                  vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                      image,\n",
    "                      np.squeeze(boxes),\n",
    "                      np.squeeze(classes).astype(np.int32),\n",
    "                      np.squeeze(scores),\n",
    "                      category_index,\n",
    "                      use_normalized_coordinates=True,min_score_thresh=.2,\n",
    "                      line_thickness=3)\n",
    "    \n",
    "                  plt.figure(figsize=(9,6))\n",
    "                  plt.imshow(image)\n",
    "                  plt.show()  \n",
    "              \n",
    "              boxes=np.squeeze(boxes)\n",
    "              classes =np.squeeze(classes)\n",
    "              scores = np.squeeze(scores)\n",
    "    \n",
    "              cls = classes.tolist()\n",
    "             \n",
    "              # Find the first occurence of traffic light detection id=10\n",
    "              idx = next((i for i, v in enumerate(cls) if v == 10.), None)\n",
    "              # If there is no detection\n",
    "              if idx == None:\n",
    "                  box=[0, 0, 0, 0]\n",
    "                  print('no detection!')\n",
    "              # If the confidence of detection is too slow, 0.3 for simulator    \n",
    "              elif scores[idx]<=0.02:\n",
    "                  box=[0, 0, 0, 0]\n",
    "                  print('low confidence:', scores[idx])\n",
    "              #If there is a detection and its confidence is high enough    \n",
    "              else:\n",
    "                  #*************corner cases***********************************\n",
    "                  dim = image.shape[0:2]\n",
    "                  box = self.box_normal_to_pixel(boxes[idx], dim)\n",
    "                  box_h = box[2] - box[0]\n",
    "                  box_w = box[3] - box[1]\n",
    "                  ratio = box_h/(box_w + 0.01)\n",
    "                  # if the box is too small, 20 pixels for simulator\n",
    "                  if (box_h <10) or (box_w<10):\n",
    "                      box =[0, 0, 0, 0]\n",
    "                      print('box too small!', box_h, box_w)\n",
    "                  # if the h-w ratio is not right, 1.5 for simulator    \n",
    "                  elif (ratio<1.5):\n",
    "                      box =[0, 0, 0, 0]\n",
    "                      print('wrong h-w ratio', ratio)\n",
    "                  else:    \n",
    "                       print(box)\n",
    "                       print('localization confidence: ', scores[idx])\n",
    "                 #****************end of corner cases***********************      \n",
    "              self.tl_box = box\n",
    "             \n",
    "        return box\n",
    "        \n",
    "    def get_classification(self, image):\n",
    "        \"\"\"Determines the color of the traffic light in the image\n",
    "        Args:\n",
    "            image (cv::Mat): cropped image containing the traffic light\n",
    "        Returns:\n",
    "            int: ID of traffic light color (specified in styx_msgs/TrafficLight)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Resize cropped \n",
    "        #img_resize = cv2.resize(image, (32, 32)) \n",
    "        img_resize = image\n",
    "        # Color map conversion\n",
    "        img_resize=cv2.cvtColor(img_resize, cv2.COLOR_BGR2RGB) \n",
    "        # Convert to four-dimension input as required by Keras\n",
    "        img_resize = np.expand_dims(img_resize, axis=0).astype('float32')\n",
    "        # Normalization\n",
    "        img_resize/=255.\n",
    "        # Prediction\n",
    "        predict = self.cls_model.predict(img_resize)\n",
    "        predict = np.squeeze(predict, axis =0)\n",
    "        # Get color classification\n",
    "        tl_color = self.signal_classes[np.argmax(predict)]\n",
    "        print(tl_color,', Classification confidence:', predict[np.argmax(predict)])\n",
    "        \n",
    "        # TrafficLight message\n",
    "        self.signal_status = tl_color\n",
    "        \n",
    "        \n",
    "        return self.signal_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'cwd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8c225b9d883e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtl_cls\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mTLClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTEST_IMAGE_PATHS\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'traffic_light_images/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_IMAGE_PATHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d51b24e30e46>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtl_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#keras classification model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'cwd' is not defined"
     ]
    }
   ],
   "source": [
    "tl_cls =TLClassifier()\n",
    "os.chdir('/home/ank/tl_ws/training_images')\n",
    "TEST_IMAGE_PATHS= glob(os.path.join('traffic_light_images/', '*.jpg'))\n",
    "        \n",
    "for i, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "    print('')\n",
    "    print('*************************************************')\n",
    "            \n",
    "    img_full = Image.open(image_path)\n",
    "    img_full_np = tl_cls.load_image_into_numpy_array(img_full)\n",
    "    img_full_np_copy = np.copy(img_full_np)\n",
    "    start = time.time()\n",
    "    b = tl_cls.get_localization(img_full_np, visual=False)\n",
    "    end = time.time()\n",
    "    print('Localization time: ', end-start)\n",
    "    start = time.time()\n",
    "    # If there is no detection or low-confidence detection\n",
    "    if np.array_equal(b, np.zeros(4)):\n",
    "        print ('unknown')\n",
    "        plt.figure(figsize=(9,6))\n",
    "        plt.imshow(img_full_np)\n",
    "        plt.show()\n",
    "    else:    \n",
    "        cv2.rectangle(img_full_np,(b[1],b[0]),(b[3],b[2]),(0,255,0),2)\n",
    "        plt.figure(figsize=(9,6))\n",
    "        plt.imshow(img_full_np)\n",
    "        plt.show()\n",
    "        img_np = cv2.resize(img_full_np_copy[b[0]:b[2], b[1]:b[3]], (32, 32)) \n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(img_np)\n",
    "        plt.show()\n",
    "        tl_cls.get_classification(img_np)\n",
    "              \n",
    "    end = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
